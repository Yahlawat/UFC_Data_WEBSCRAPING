{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Lists and Parameters\n",
    "\n",
    "We set up:\n",
    "- `pages`: the number of pages to scrape from [ufcstats.com](http://ufcstats.com)\n",
    "- `event_links`: an empty list to hold event URLs.\n",
    "- `fights`: an empty list for storing parsed fight details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = 1  # Set the number of pages to scrape\n",
    "event_links = []  # List to store event links separately\n",
    "fights = []  # List to store fight details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Scrapy Spider\n",
    "\n",
    "This class, `UfcSpider`, handles the logic for:\n",
    "1. Navigating through the UFCStats pages.\n",
    "2. Extracting event links.\n",
    "3. Visiting each event to get fight URLs, dates, and locations.\n",
    "4. Finally, parsing detailed fight stats (fighter names, round, result, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UfcSpider(scrapy.Spider):\n",
    "    name = \"ufc_spider\"  # Name of the spider\n",
    "\n",
    "    def start_requests(self):\n",
    "        \"\"\"\n",
    "        Start by sending requests to the UFC statistics events page for each page.\n",
    "        \"\"\"\n",
    "        for p in range(1, pages + 1):\n",
    "            url = f\"http://ufcstats.com/statistics/events/completed?page={p}\"\n",
    "            yield scrapy.Request(url=url, callback=self.parse_main)\n",
    "\n",
    "    def parse_main(self, response):\n",
    "        \"\"\"\n",
    "        Extract event links from the page and follow them.\n",
    "        \"\"\"\n",
    "        event_links_on_page = response.css(\n",
    "            \"a.b-link.b-link_style_black::attr(href)\"\n",
    "        ).extract()\n",
    "\n",
    "        for e in event_links_on_page:\n",
    "            event_links.append({\"event_link\": e})  # Store event link\n",
    "            yield response.follow(url=e, callback=self.parse_events)\n",
    "\n",
    "    def parse_events(self, response):\n",
    "        \"\"\"\n",
    "        Extract fight links, date, and location from the event page.\n",
    "        Follow each fight link to extract fight details.\n",
    "        \"\"\"\n",
    "        fight_links = response.css(\"a.b-flag.b-flag_style_green::attr(href)\").extract()\n",
    "        date = response.css(\"li.b-list__box-list-item:nth-child(1)::text\").extract()[1]\n",
    "        location = response.css(\n",
    "            \"li.b-list__box-list-item:nth-child(2)::text\"\n",
    "        ).extract()[1]\n",
    "\n",
    "        for f in fight_links:\n",
    "            yield response.follow(\n",
    "                url=f,\n",
    "                callback=self.parse_fights,\n",
    "                meta={\"date\": date, \"location\": location},\n",
    "            )\n",
    "\n",
    "    def parse_fights(self, response):\n",
    "        \"\"\"\n",
    "        Extract fight details such as fighters, results, and statistics.\n",
    "        \"\"\"\n",
    "        date = response.meta[\"date\"]  # Extract date from metadata\n",
    "        location = response.meta[\"location\"]  # Extract location from metadata\n",
    "\n",
    "        # Extract fighter details\n",
    "        fighter_details = response.css(\"div.b-fight-details__person\")\n",
    "        win_loss_1, win_loss_2 = fighter_details.css(\n",
    "            \"i.b-fight-details__person-status::text\"\n",
    "        ).extract()[0:2]\n",
    "        name_1, name_2 = fighter_details.css(\"h3 > a::text\").extract()[0:2]\n",
    "        stage_name_1, stage_name_2 = fighter_details.css(\n",
    "            \"p.b-fight-details__person-title::text\"\n",
    "        ).extract()[0:2]\n",
    "\n",
    "        # Extract fight details\n",
    "        fight_details = response.css(\"div.b-fight-details__content\")\n",
    "        method = fight_details.css(\n",
    "            \"p:nth-child(1) > i.b-fight-details__text-item_first > i:nth-child(2)::text\"\n",
    "        ).get()\n",
    "        round_num = fight_details.css(\n",
    "            \"p:nth-child(1) > i:nth-child(2)::text\"\n",
    "        ).extract()[1]\n",
    "        time = fight_details.css(\"p:nth-child(1) > i:nth-child(3)::text\").extract()[1]\n",
    "        time_format = fight_details.css(\n",
    "            \"p:nth-child(1) > i:nth-child(4)::text\"\n",
    "        ).extract()[1]\n",
    "        referee = fight_details.css(\n",
    "            \"p:nth-child(1) > i:nth-child(5) > span::text\"\n",
    "        ).get()\n",
    "        details = fight_details.css(\"p:nth-child(2)::text\").extract()[1].strip()\n",
    "\n",
    "        # Extract fight statistics\n",
    "        stats_table = response.css(\n",
    "            \"body > section > div > div > section:nth-child(4) > table > tbody\"\n",
    "        )\n",
    "        kd_1, kd_2 = stats_table.css(\"td:nth-child(2) p::text\").extract()[0:2]\n",
    "        sig_str_1, sig_str_2 = stats_table.css(\"td:nth-child(3) p::text\").extract()[0:2]\n",
    "        total_str_1, total_str_2 = stats_table.css(\"td:nth-child(5) p::text\").extract()[\n",
    "            0:2\n",
    "        ]\n",
    "\n",
    "        # Append all extracted fight details to the fights list\n",
    "        fights.append(\n",
    "            {\n",
    "                \"fight_link\": response.url,\n",
    "                \"date\": date,\n",
    "                \"location\": location,\n",
    "                \"method\": method,\n",
    "                \"round\": round_num,\n",
    "                \"time\": time,\n",
    "                \"time_format\": time_format,\n",
    "                \"referee\": referee,\n",
    "                \"details\": details,\n",
    "                \"name_1\": name_1,\n",
    "                \"name_2\": name_2,\n",
    "                \"stage_name_1\": stage_name_1,\n",
    "                \"stage_name_2\": stage_name_2,\n",
    "                \"win_loss_1\": win_loss_1,\n",
    "                \"win_loss_2\": win_loss_2,\n",
    "                \"kd_1\": kd_1,\n",
    "                \"kd_2\": kd_2,\n",
    "                \"sig_str_1\": sig_str_1,\n",
    "                \"sig_str_2\": sig_str_2,\n",
    "                \"total_str_1\": total_str_1,\n",
    "                \"total_str_2\": total_str_2,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Scrapy Spider\n",
    "\n",
    "Create a `CrawlerProcess` instance, add our spider, and start the crawling process.\n",
    "This begins the full web-scraping routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = CrawlerProcess()\n",
    "process.crawl(UfcSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Results to DataFrames\n",
    "\n",
    "After scraping, we have two lists: `event_links` and `fights`.\n",
    "Here we create pandas DataFrames for further processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_links_df = pd.DataFrame(event_links)\n",
    "fights_df = pd.DataFrame(fights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the DataFrame Strings\n",
    "\n",
    "We apply a `lambda` function to **strip whitespace** from any string columns in the `fights_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fights_df = fights_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Output Directory\n",
    "\n",
    "Here we define where we want to save our CSV files.\n",
    "Make sure the path is correct for your system or adjust it as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"C:\\\\Users\\\\ahlaw\\\\OneDrive - UBC\\\\Documents\\\\vscode\\\\Projects\\\\UFC_data_webscraping\\\\Data\\\\Raw\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrames as CSV Files\n",
    "\n",
    "Finally, we export both DataFrames to CSV.\n",
    "These files will appear in the specified `save_path` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_links_df.to_csv(save_path + \"event_links.csv\", index=False)\n",
    "fights_df.to_csv(save_path + \"fight_details.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Success Message\n",
    "\n",
    "A quick confirmation that everything ran smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrames saved successfully in:\", save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
